{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto-encoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWlUD3GcmOJoK9bjxrdJh5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hgaiji/GoogleColab/blob/main/auto_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxbZWFCPW4vD"
      },
      "source": [
        "#　パッケージのimport\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Input, Dense, Lambda, Reshape\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.datasets import mnist\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_wKqYQhXRwJ"
      },
      "source": [
        "#  ハイパラメータの設定\n",
        "batch_size = 100\n",
        "original_dim = 784\n",
        "latent_dim = 2\n",
        "intermediate_dim = 256\n",
        "epochs = 50\n",
        "epsilon_std = 1.0"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbn1ngP3YPMn",
        "outputId": "2578dd61-5254-4e03-964b-2d73b5735281"
      },
      "source": [
        "def sampling(args: tuple):\n",
        "    # we grab the variables from the tuple\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
        "                              stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "# # エンコーダの生成\n",
        "# x = Input(shape=(original_dim),name=\"input\")\n",
        "# # 中間層\n",
        "# h = Dense(intermediate_dim, activation=\"relu\", name=\"encoding\")(x)\n",
        "# #潜在空間の平均　mean を定義\n",
        "# z_mean = Dense(latent_dim, name=\"mean\")(h)\n",
        "# print(z_mean)\n",
        "# # 潜在空間でのlog分散(log variance)を定義\n",
        "# z_log_var = Dense(latent_dim, name=\"log-variance\")(h)\n",
        "\n",
        "# z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# encoder = Model(x, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "# input to our encoder\n",
        "x = Input(shape=(original_dim,), name=\"input\")\n",
        "# intermediate layer\n",
        "h = Dense(intermediate_dim, activation='relu', name=\"encoding\")(x)\n",
        "# defining the mean of the latent space\n",
        "z_mean = Dense(latent_dim, name=\"mean\")(h)\n",
        "# defining the log variance of the latent space\n",
        "z_log_var = Dense(latent_dim, name=\"log-variance\")(h)\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "# defining the encoder as a keras model\n",
        "encoder = Model(x, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "# print out summary of what we just did\n",
        "encoder.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 784)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoding (Dense)                (None, 256)          200960      input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "mean (Dense)                    (None, 2)            514         encoding[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "log-variance (Dense)            (None, 2)            514         encoding[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 2)            0           mean[0][0]                       \n",
            "                                                                 log-variance[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 201,988\n",
            "Trainable params: 201,988\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weXCO8RJae31",
        "outputId": "5ebac026-9113-4da3-b01d-77e2e3339795"
      },
      "source": [
        "# # デコーダーの記述\n",
        "# input_decoder = Input(shape=(latent_dim,), name=\"decorder=input\")\n",
        "# #潜在空間から途中の次元数にする\n",
        "# decoder_h = Dense(intermediate_dim, activation='relu',name=\"decorder_h\")(input_decoder)\n",
        "# x_decoed = Dense(original_dim, activation='sigmoid',name=\"flat_decoded\")(decoder_h)\n",
        "# # デコーダーをkerasのモデルとして定義\n",
        "# decoder = Model(input_decoder, x_decoed, name=\"decoder\")\n",
        "# decoder.summary()\n",
        "\n",
        "\n",
        "# Input to the decoder\n",
        "input_decoder = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
        "# taking the latent space to intermediate dimension\n",
        "decoder_h = Dense(intermediate_dim, activation='relu', name=\"decoder_h\")(input_decoder)\n",
        "# getting the mean from the original dimension\n",
        "x_decoded = Dense(original_dim, activation='sigmoid', name=\"flat_decoded\")(decoder_h)\n",
        "# defining the decoder as a keras model\n",
        "decoder = Model(input_decoder, x_decoded, name=\"decoder\")\n",
        "decoder.summary()\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_h (Dense)            (None, 256)               768       \n",
            "_________________________________________________________________\n",
            "flat_decoded (Dense)         (None, 784)               201488    \n",
            "=================================================================\n",
            "Total params: 202,256\n",
            "Trainable params: 202,256\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9q9ZEcew8l6",
        "outputId": "d857a6d4-278a-448f-f8ce-dfaf501e5933"
      },
      "source": [
        "# # モデルをまとめる\n",
        "# # 結果を得る　３つ目の要素はサンプリングされたｚです\n",
        "# output_combined = decoder(encoder(x)[2])\n",
        "# # 入力と全体の出力を結びつける\n",
        "# vae = Model(x, output_combined)\n",
        "# vae.summary()\n",
        "\n",
        "# grab the output. Recall, that we need to grab the 3rd element our sampling z\n",
        "output_combined = decoder(encoder(x)[2])\n",
        "# link the input and the overall output\n",
        "vae = Model(x, output_combined)\n",
        "# print out what the overall model looks like\n",
        "vae.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder (Functional)         [(None, 2), (None, 2), (N 201988    \n",
            "_________________________________________________________________\n",
            "decoder (Functional)         (None, 784)               202256    \n",
            "=================================================================\n",
            "Total params: 404,244\n",
            "Trainable params: 404,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lZF9jGc7ztH"
      },
      "source": [
        "\n",
        "Model??"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyO2NnF1zwj6",
        "outputId": "df8404bf-e5c8-4fe2-9251-b052e73d78c4"
      },
      "source": [
        "\n",
        "def vae_loss(x: tf.Tensor, x_decoded_mean: tf.Tensor,\n",
        "            z_log_var=z_log_var, z_mean=z_mean,\n",
        "            original_dim=original_dim):\n",
        "    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
        "    kl_loss = - 0.5 * K.sum(\n",
        "        1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    vae_loss = K.mean(xent_loss + kl_loss)\n",
        "    return vae_loss\n",
        "\n",
        "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
        "vae.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder (Functional)         [(None, 2), (None, 2), (N 201988    \n",
            "_________________________________________________________________\n",
            "decoder (Functional)         (None, 784)               202256    \n",
            "=================================================================\n",
            "Total params: 404,244\n",
            "Trainable params: 404,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqiLy-Cr7wC9"
      },
      "source": [
        "\n",
        "Model??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OunySgui1Sbf"
      },
      "source": [
        "# 訓練データと検証用データの分離\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NyR4dJ7U3c4t",
        "outputId": "3662227d-3276-4083-cdcc-5770c09464bf"
      },
      "source": [
        "vae.fit(x_train, x_train,shuffle=True,epochs=epochs,batch_size=batch_size)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-4822d772e306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:238 __call__\n        total_loss_metric_value, sample_weight=batch_dim)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:177 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:364 update_state  **\n        sample_weight, values)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/weights_broadcast_ops.py:155 broadcast_weights\n        values = ops.convert_to_tensor(values, name=\"values\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:265 constant\n        allow_broadcast=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:435 make_tensor_proto\n        values = np.asarray(values)\n    /usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83 asarray\n        return array(a, dtype, copy=False, order=order)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/keras_tensor.py:274 __array__\n        'Cannot convert a symbolic Keras input/output to a numpy array. '\n\n    TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tx1E04o43sHe",
        "outputId": "a334e278-9263-448e-f9e0-f4dc6efaa30e"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "# This is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# This is our input image\n",
        "input_img = keras.Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "\n",
        "# This model maps an input to its encoded representation\n",
        "encoder = keras.Model(input_img, encoded)\n",
        "\n",
        "# This is our encoded (32-dimensional) input\n",
        "encoded_input = keras.Input(shape=(encoding_dim,))\n",
        "# Retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# Create the decoder model\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Encode and decode some digits\n",
        "# Note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "                               \n",
        "\n",
        "                               # Use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # How many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "Epoch 1/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3789 - val_loss: 0.1865\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1784 - val_loss: 0.1534\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1492 - val_loss: 0.1335\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1312 - val_loss: 0.1204\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1197 - val_loss: 0.1122\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1123 - val_loss: 0.1065\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1069 - val_loss: 0.1027\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1028 - val_loss: 0.0993\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1002 - val_loss: 0.0971\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0979 - val_loss: 0.0955\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0964 - val_loss: 0.0945\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0957 - val_loss: 0.0938\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0950 - val_loss: 0.0934\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0947 - val_loss: 0.0931\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0943 - val_loss: 0.0929\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0939 - val_loss: 0.0927\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0941 - val_loss: 0.0926\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0939 - val_loss: 0.0925\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0936 - val_loss: 0.0923\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0936 - val_loss: 0.0923\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0933 - val_loss: 0.0923\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0932 - val_loss: 0.0921\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0921\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0919\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0918\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0916\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0917\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0916\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0917\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.0916\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0916\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0915\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0915\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0925 - val_loss: 0.0915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHbBHt3t83Hb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}